{"cells":[{"cell_type":"markdown","source":["# Reconstructing the Full Test Images\n","\n","Now that we trained the model and predicted what the test crops will look like, it is time to focus on reconstruction. Using our predicted crops, we will stitch them back together to create complete masks we can observe."],"metadata":{"id":"XIkAdZd6MFP-"}},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZYegP_LRcSc","executionInfo":{"status":"ok","timestamp":1721459206256,"user_tz":420,"elapsed":65971,"user":{"displayName":"Mohssen Kassir","userId":"16622663070587836490"}},"outputId":"0b8fb2c0-3a2f-4e75-b3da-040c3149dc8d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"7OplkzjnQY9z","executionInfo":{"status":"ok","timestamp":1721459208308,"user_tz":420,"elapsed":2056,"user":{"displayName":"Mohssen Kassir","userId":"16622663070587836490"}}},"outputs":[],"source":["# Import\n","import os\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"markdown","source":["The following function is all we need this time:"],"metadata":{"id":"TCMtDnCBNWOn"}},{"cell_type":"code","source":["# This does all the heavylifting and recreates the images\n","# Instead of averaging, each pixel is determined by what percentage of the crops outline that pixel as white, by the variable vote_percentage\n","\n","def reconstruct_images_from_crops(crops_dir, save_dir, original_size=(512, 512), crop_size=(48, 48), stride=16, crops_per_image=900, vote_percentage=0.5):\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # Get the list of crop files and sort them\n","    crop_files = sorted([f for f in os.listdir(crops_dir) if f.endswith('.jpg')])\n","\n","    # Extract unique base names by cutting off the '_crop' at the end\n","    base_names = {os.path.splitext(f)[0].rsplit('_crop', 1)[0] for f in crop_files}\n","\n","    # Iterate through each base name\n","    for base_name in base_names:\n","        print(f\"Processing base name: {base_name}\")  # Debug statement\n","\n","        # Create arrays for accumulating the image and counting overlaps\n","        vote_array = np.zeros((original_size[0], original_size[1]), dtype=np.int32)  # ADDED\n","        overlap_count = np.zeros((original_size[0], original_size[1]), dtype=np.int32)\n","\n","        # Iterate through the crop files for the current base name\n","        for crop_number in range(1, crops_per_image + 1):\n","            crop_file = f\"{base_name}_crop{crop_number}.jpg\"\n","            if crop_file not in crop_files:\n","                continue  # Skip if the crop file does not exist\n","\n","            crop_path = os.path.join(crops_dir, crop_file)\n","            crop = np.array(Image.open(crop_path).convert('L'))  # ADJUSTED: Convert to grayscale\n","\n","            # Calculate the position in the original image\n","            num_crops_per_row = (original_size[1] - crop_size[1]) // stride + 1\n","            row = (crop_number - 1) // num_crops_per_row\n","            col = (crop_number - 1) % num_crops_per_row\n","            y = row * stride\n","            x = col * stride\n","\n","            # Accumulate the vote in the vote_array\n","            vote_array[y:y+crop_size[0], x:x+crop_size[1]] += (crop > 127).astype(np.int32)  # ADDED: Count votes\n","            overlap_count[y:y+crop_size[0], x:x+crop_size[1]] += 1\n","\n","        # Apply majority voting with 50% threshold\n","        vote_threshold = (overlap_count * vote_percentage).astype(np.int32)  # ADDED: Calculate threshold based on percentage\n","        final_image = (vote_array > vote_threshold).astype(np.uint8) * 255  # ADDED: Apply voting threshold and convert to binary image\n","\n","        # Save the reconstructed image\n","        save_path = os.path.join(save_dir, f\"{base_name}_reconstructed.jpg\")\n","        Image.fromarray(final_image).save(save_path, format='JPEG')\n","        print(base_name, \"reconstructed\")"],"metadata":{"id":"ZxFXAgh_jvMA","executionInfo":{"status":"ok","timestamp":1721459208310,"user_tz":420,"elapsed":6,"user":{"displayName":"Mohssen Kassir","userId":"16622663070587836490"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Reconstruct Test Images\n","base_path = '/content/drive/My Drive/ML_projects/VesselProject/RetinalImages'\n","predicted_masks_dir = os.path.join(base_path, 'Predicted_masks')\n","save_reconstructed_dir = os.path.join(base_path, 'Reconstructed_masks')\n","reconstruct_images_from_crops(predicted_masks_dir, save_reconstructed_dir, crop_size=(128, 128), stride=32, crops_per_image=169, vote_percentage=0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59rYkmqpR0lB","executionInfo":{"status":"ok","timestamp":1721459414217,"user_tz":420,"elapsed":205912,"user":{"displayName":"Mohssen Kassir","userId":"16622663070587836490"}},"outputId":"5895e9ff-9877-4265-c449-50f0ebea9582"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing base name: 33_DRIVE\n","33_DRIVE reconstructed\n","Processing base name: Image_01R_CHASE\n","Image_01R_CHASE reconstructed\n","Processing base name: 13_g_HRF\n","13_g_HRF reconstructed\n","Processing base name: Image_02L_CHASE\n","Image_02L_CHASE reconstructed\n","Processing base name: Image_03L_CHASE\n","Image_03L_CHASE reconstructed\n","Processing base name: 15_dr_HRF\n","15_dr_HRF reconstructed\n","Processing base name: 37_DRIVE\n","37_DRIVE reconstructed\n","Processing base name: 14_g_HRF\n","14_g_HRF reconstructed\n","Processing base name: Image_03R_CHASE\n","Image_03R_CHASE reconstructed\n","Processing base name: 15_h_HRF\n","15_h_HRF reconstructed\n","Processing base name: 13_h_HRF\n","13_h_HRF reconstructed\n","Processing base name: 15_g_HRF\n","15_g_HRF reconstructed\n","Processing base name: 14_h_HRF\n","14_h_HRF reconstructed\n","Processing base name: 36_DRIVE\n","36_DRIVE reconstructed\n","Processing base name: 13_dr_HRF\n","13_dr_HRF reconstructed\n","Processing base name: 14_dr_HRF\n","14_dr_HRF reconstructed\n","Processing base name: 35_DRIVE\n","35_DRIVE reconstructed\n","Processing base name: Image_01L_CHASE\n","Image_01L_CHASE reconstructed\n","Processing base name: Image_02R_CHASE\n","Image_02R_CHASE reconstructed\n","Processing base name: 32_DRIVE\n","32_DRIVE reconstructed\n"]}]},{"cell_type":"markdown","source":["## Show the Reconstruction\n","\n","In addition, this will show what all 20 test masks look like next to their ground truth counterparts"],"metadata":{"id":"JGohlKTYNjIf"}},{"cell_type":"code","source":["base_path = '/content/drive/My Drive/ML_projects/VesselProject/RetinalImages'\n","image_dir = os.path.join(base_path, 'Test', 'Images')\n","mask_dir = os.path.join(base_path, 'Processed', 'Test', 'Masks')\n","reconstructed_dir = os.path.join(base_path, 'Reconstructed_masks')\n","\n","# Get the list of reconstructed images\n","reconstructed_images = [f for f in os.listdir(reconstructed_dir) if f.endswith('_reconstructed.jpg')]\n","\n","acc_list = []\n","\n","# Iterate through the reconstructed images\n","for reconstructed_image in reconstructed_images:\n","    # Extract the base name\n","    base_name = reconstructed_image.split('_reconstructed')[0]\n","\n","    # Load the corresponding image, mask, and reconstructed image\n","    image_path = next((os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.startswith(base_name)), None)\n","    mask_path = next((os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.startswith(base_name)), None)\n","    reconstructed_path = os.path.join(reconstructed_dir, reconstructed_image)\n","\n","    image = Image.open(image_path)\n","    mask = Image.open(mask_path).convert('L')  # Convert mask to grayscale\n","    reconstructed = Image.open(reconstructed_path)\n","\n","    mask_np = np.array(mask)\n","    reconstructed_np = np.array(reconstructed)\n","\n","    # Calculate accuracy\n","    correct_predictions = np.sum(mask_np == reconstructed_np)\n","    total_pixels = mask_np.size\n","    accuracy = correct_predictions / total_pixels\n","    print(f\"Accuracy for {base_name}: {accuracy:.4f}\")\n","    acc_list.append(accuracy)\n","\n","    # Display the images side by side\n","    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","    axes[0].imshow(image)\n","    axes[0].set_title('Original Image')\n","    axes[1].imshow(mask, cmap='gray')\n","    axes[1].set_title('Ground Truth Mask')\n","    axes[2].imshow(reconstructed, cmap='gray')\n","    axes[2].set_title('Reconstructed Mask')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","print('AVERAGE ACCURACY:', np.mean(acc_list))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1kq8GWQqcgvR_2_DFpq3cMpF9qpBRF1kF"},"id":"svtRukOkS3Hj","executionInfo":{"status":"ok","timestamp":1721459471380,"user_tz":420,"elapsed":57181,"user":{"displayName":"Mohssen Kassir","userId":"16622663070587836490"}},"outputId":"10520dcf-f87b-45ab-ab4c-22883a8484b4"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## There you have it! Thank you for reviewing my project!\n","\n","As you can see, the reconstructed masks capture most of the large vessels well and mantain an accuracy close to 80%. This makes it very useful and impactful in the analysis of retinal images\n","\n","Unfortunately, it does have a weekness in identifying the smaller vessels, and in a few cases it introduces some distracting noise. However, the visuals are mostly useful and heavily reflect the vessels of the orignal images.\n","\n","Thank you very much, and stay tuned to my github for more excited projects in the future!"],"metadata":{"id":"rBjJ_1DZN4Dy"}}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}